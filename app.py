import streamlit as st
import pandas as pd
import pdfplumber
import collections
import re
from PIL import Image # å°å…¥ Pillow å‡½å¼åº«
import pytesseract # å°å…¥ pytesseract
from img2table.document import PDF as Img2TablePDF # å°å…¥ img2table çš„ PDF é¡
from img2table.ocr import TesseractOCR # å°å…¥ TesseractOCR
import io # å°å…¥ io æ¨¡çµ„ç”¨æ–¼è™•ç† BytesIO

# --- å…¨åŸŸå®šç¾©çš„é—œéµå­—åˆ—è¡¨ ---
credit_column_keywords = ["å­¸åˆ†", "å­¸åˆ†æ•¸", "å­¸åˆ†(GPA)", "å­¸ åˆ†", "Credits", "Credit", "å­¸åˆ†æ•¸(å­¸åˆ†)", "ç¸½å­¸åˆ†"]
subject_column_keywords = ["ç§‘ç›®åç¨±", "èª²ç¨‹åç¨±", "Course Name", "Subject Name", "ç§‘ç›®", "èª²ç¨‹"]
gpa_column_keywords = ["GPA", "æˆç¸¾", "Grade", "gpa(æ•¸å€¼)"]
year_column_keywords = ["å­¸å¹´", "year", "å­¸ å¹´", "å­¸å¹´åº¦"]
semester_column_keywords = ["å­¸æœŸ", "semester", "å­¸ æœŸ"]
course_code_keywords = ["é¸èª²ä»£è™Ÿ", "èª²è™Ÿ", "èª²ç¨‹ä»£ç¢¼", "course code"]

# å°‡æ‰€æœ‰æ¨™é ­é—œéµå­—æ‰å¹³åŒ–ç‚ºä¸€å€‹åˆ—è¡¨ï¼Œç”¨æ–¼æ›´å»£æ³›çš„æ¨™é ­è¡Œåˆ¤æ–·
all_header_keywords_flat_lower = set([
    re.sub(r'[\s\n]+', '', k.lower()) for k in
    credit_column_keywords +
    subject_column_keywords +
    gpa_column_keywords +
    year_column_keywords +
    semester_column_keywords +
    course_code_keywords
])

# ä¸åŠæ ¼æˆç¸¾çš„å®šç¾©
failing_grades = ["D", "D-", "E", "F", "X", "ä¸é€šé", "æœªé€šé", "ä¸åŠæ ¼", "fail", "failed"]

# å®šç¾©æˆç¸¾èˆ‡å­¸åˆ†çš„å°æ‡‰é—œä¿‚ (å¯æ ¹æ“šå­¸æ ¡çš„è©•åˆ†ç³»çµ±èª¿æ•´)
grade_to_gpa = {
    'A+': 4.3, 'A': 4.0, 'A-': 3.7,
    'B+': 3.3, 'B': 3.0, 'B-': 2.7,
    'C+': 2.3, 'C': 2.0, 'C-': 1.7,
    'D+': 1.3, 'D': 1.0, 'D-': 0.7,
    'E': 0.0, 'F': 0.0, 'X': 0.0,
    'ä¸åŠæ ¼': 0.0, 'ä¸é€šé': 0.0,
}
passing_grades_keywords = ['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'é€šé', 'æŠµå…']


# --- è¼”åŠ©å‡½æ•¸ ---
def normalize_text(cell_content):
    """
    æ¨™æº–åŒ–å¾ pdfplumber æˆ– OCR æå–çš„å–®å…ƒæ ¼å…§å®¹ã€‚
    è™•ç† None å€¼ã€pdfplumber çš„ Text ç‰©ä»¶å’Œæ™®é€šå­—ä¸²ã€‚
    å°‡å¤šå€‹ç©ºç™½å­—å…ƒï¼ˆåŒ…æ‹¬æ›è¡Œã€å…¨å½¢ç©ºæ ¼ï¼‰æ›¿æ›ç‚ºå–®å€‹ç©ºæ ¼ï¼Œä¸¦å»é™¤å…©ç«¯ç©ºç™½ã€‚
    """
    if cell_content is None:
        return ""

    text = ""
    if hasattr(cell_content, 'text'):
        text = str(cell_content.text)
    elif isinstance(cell_content, str):
        text = cell_content
    else:
        text = str(cell_content)

    return re.sub(r'[\s\u3000]+', ' ', text).strip()


def make_unique_columns(columns_list):
    """
    å°‡åˆ—è¡¨ä¸­çš„æ¬„ä½åç¨±è½‰æ›ç‚ºå”¯ä¸€çš„åç¨±ï¼Œè™•ç†é‡è¤‡å’Œç©ºå­—ä¸²ã€‚
    å¦‚æœé‡åˆ°é‡è¤‡æˆ–ç©ºå­—ä¸²ï¼Œæœƒæ·»åŠ å¾Œç¶´ (ä¾‹å¦‚ 'Column_1', 'æ¬„ä½_2')ã€‚
    æ­¤ç‰ˆæœ¬æœƒå˜—è©¦å»é™¤åŸå§‹åˆ—åä¸­çš„æ›è¡Œç¬¦å’Œå¤šé¤˜ç©ºæ ¼å¾Œå†è™•ç†å”¯ä¸€æ€§ã€‚
    """
    seen = collections.defaultdict(int)
    unique_columns = []
    for col in columns_list:
        # å…ˆé€²è¡Œæ¨™æº–åŒ–ï¼Œå»é™¤æ›è¡Œå’Œå¤šé¤˜ç©ºæ ¼
        original_col_cleaned = normalize_text(col)

        if not original_col_cleaned or len(original_col_cleaned) < 2: # å°æ–¼éå¸¸çŸ­æˆ–ç©ºç™½çš„åˆ—åçµ¦äºˆé€šç”¨å
            name_base = "Column"
            current_idx = 1
            while f"{name_base}_{current_idx}" in unique_columns:
                current_idx += 1
            name = f"{name_base}_{current_idx}"
        else:
            name = original_col_cleaned

        final_name = name
        counter = seen[name]
        while final_name in unique_columns:
            counter += 1
            final_name = f"{name}_{counter}"

        unique_columns.append(final_name)
        seen[name] = counter

    return unique_columns


def parse_credit_and_gpa(text):
    """
    å¾å–®å…ƒæ ¼æ–‡æœ¬ä¸­è§£æå­¸åˆ†å’Œ GPAã€‚
    è€ƒæ…® "A 2" (GPAåœ¨å·¦ï¼Œå­¸åˆ†åœ¨å³) å’Œ "2 A" (å­¸åˆ†åœ¨å·¦ï¼ŒGPAåœ¨å³) çš„æƒ…æ³ã€‚
    è¿”å› (å­¸åˆ†, GPA)ã€‚å¦‚æœè§£æå¤±æ•—ï¼Œè¿”å› (0.0, "")ã€‚
    """
    text_clean = normalize_text(text).lower()

    # é¦–å…ˆæª¢æŸ¥æ˜¯å¦æ˜¯ã€Œé€šéã€æˆ–ã€ŒæŠµå…ã€ç­‰é—œéµè©
    if "é€šé" in text_clean or "æŠµå…" in text_clean or "pass" in text_clean or "exempt" in text_clean:
        return 0.0, text_clean # è¿”å›0å­¸åˆ†å’ŒåŸå§‹æ–‡å­—ï¼Œè®“å¾Œé¢åˆ¤æ–·ç‚ºç‰¹æ®Šæˆç¸¾

    credit = 0.0
    gpa = ""

    # å˜—è©¦åŒ¹é… "GPA å­¸åˆ†" æ¨¡å¼ (ä¾‹å¦‚ "A 2", "C- 3")
    match_gpa_credit = re.match(r'([a-z][+\-]?)\s*(\d+(\.\d+)?)', text_clean)
    if match_gpa_credit:
        try:
            gpa = match_gpa_credit.group(1).upper()
            credit = float(match_gpa_credit.group(2))
            if 0.0 <= credit <= 5.0:  # å­¸åˆ†ç¯„åœå…è¨±0å­¸åˆ†
                return credit, gpa
        except ValueError:
            pass

    # å˜—è©¦åŒ¹é… "å­¸åˆ† GPA" æ¨¡å¼ (ä¾‹å¦‚ "2 A", "3 B-")
    match_credit_gpa = re.match(r'(\d+(\.\d+)?)\s*([a-z][+\-]?)', text_clean)
    if match_credit_gpa:
        try:
            credit = float(match_credit_gpa.group(1))
            gpa = match_credit_gpa.group(3).upper()
            if 0.0 <= credit <= 5.0:  # å­¸åˆ†ç¯„åœå…è¨±0å­¸åˆ†
                return credit, gpa
        except ValueError:
            pass

    # å˜—è©¦åªåŒ¹é…å­¸åˆ† (ç´”æ•¸å­—)
    credit_only_match = re.search(r'(\d+(\.\d+)?)', text_clean)
    if credit_only_match:
        try:
            credit = float(credit_only_match.group(1))
            if 0.0 <= credit <= 5.0:
                # å¦‚æœåªæå–åˆ°å­¸åˆ†ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰å–®ç¨çš„GPAå­—æ¯åœ¨é™„è¿‘ï¼ˆä¸åœ¨æ•¸å­—æ—é‚Šï¼‰
                gpa_only_match = re.search(r'([a-z][+\-]?)', text_clean.replace(credit_only_match.group(0), ''))
                if gpa_only_match:
                    gpa = gpa_only_match.group(1).upper()
                return credit, gpa
        except ValueError:
            pass

    # å˜—è©¦åªåŒ¹é… GPA (ç´”å­—æ¯)
    gpa_only_match = re.search(r'([a-z][+\-]?)', text_clean)
    if gpa_only_match:
        return 0.0, gpa_only_match.group(1).upper()

    return 0.0, ""


def is_grades_table(df):
    """
    åˆ¤æ–·ä¸€å€‹ DataFrame æ˜¯å¦ç‚ºæœ‰æ•ˆçš„æˆç¸¾å–®è¡¨æ ¼ã€‚
    é€éæª¢æŸ¥æ˜¯å¦å­˜åœ¨é æœŸçš„æ¬„ä½é—œéµå­—å’Œæ•¸æ“šå…§å®¹æ¨¡å¼ä¾†åˆ¤æ–·ã€‚
    """
    if df.empty or len(df.columns) < 3:
        return False

    # Normalize column names for keyword matching
    normalized_columns = {normalize_text(col).lower().replace(' ', '').replace('\n', ''): col for col in df.columns.tolist()}

    has_credit_col_header = any(any(k in norm_col for k in [kw.lower().replace(' ', '').replace('\n', '') for kw in credit_column_keywords]) for norm_col in normalized_columns.keys())
    has_gpa_col_header = any(any(k in norm_col for k in [kw.lower().replace(' ', '').replace('\n', '') for kw in gpa_column_keywords]) for norm_col in normalized_columns.keys())
    has_subject_col_header = any(any(k in norm_col for k in [kw.lower().replace(' ', '').replace('\n', '') for kw in subject_column_keywords]) for norm_col in normalized_columns.keys())
    has_year_col_header = any(any(k in norm_col for k in [kw.lower().replace(' ', '').replace('\n', '') for kw in year_column_keywords]) for norm_col in normalized_columns.keys())
    has_semester_col_header = any(any(k in norm_col for k in [kw.lower().replace(' ', '').replace('\n', '') for kw in semester_column_keywords]) for norm_col in normalized_columns.keys())
    has_course_code_col_header = any(any(k in norm_col for k in [kw.lower().replace(' ', '').replace('\n', '') for kw in course_code_keywords]) for norm_col in normalized_columns.keys())


    if has_subject_col_header and (has_credit_col_header or has_gpa_col_header) and has_year_col_header and has_semester_col_header:
        st.info(f"åµæ¸¬åˆ°ç¬¦åˆæˆç¸¾å–®ç‰¹å¾µçš„è¡¨æ ¼å…§å®¹ (æ¨™é ­ç¬¦åˆ: ç§‘ç›®: {has_subject_col_header}, å­¸å¹´: {has_year_col_header}, å­¸æœŸ: {has_semester_col_header}, å­¸åˆ†/GPA: {has_credit_col_header or has_gpa_col_header})")
        return True

    found_year_by_content = False
    found_semester_by_content = False
    found_subject_by_content = False
    found_credit_or_gpa_by_content = False
    found_course_code_by_content = False

    sample_rows_df = df.head(min(len(df), 20))

    for col_name in df.columns:
        sample_data = sample_rows_df[col_name].apply(normalize_text).tolist()
        total_sample_count = len(sample_data)
        if total_sample_count == 0:
            continue

        if not found_year_by_content:
            year_like_cells = sum(1 for item_str in sample_data if (item_str.isdigit() and (len(item_str) == 3 or len(item_str) == 4)))
            if year_like_cells / total_sample_count >= 0.6:
                found_year_by_content = True

        if not found_semester_by_content:
            semester_like_cells = sum(1 for item_str in sample_data if item_str.lower() in ["ä¸Š", "ä¸‹", "æ˜¥", "å¤", "ç§‹", "å†¬", "1", "2", "3", "æ˜¥å­£", "å¤å­£", "ç§‹å­£", "å†¬å­£", "spring", "summer", "fall", "winter"])
            if semester_like_cells / total_sample_count >= 0.6:
                found_semester_by_content = True
        
        if not found_course_code_by_content:
            course_code_like_cells = sum(1 for item_str in sample_data if re.match(r'^[A-Za-z0-9]{3,8}$', item_str) and not item_str.isdigit())
            if course_code_like_cells / total_sample_count >= 0.3:
                found_course_code_by_content = True

        if not found_subject_by_content:
            subject_like_cells = sum(1 for item_str in sample_data
                                     if re.search(r'[\u4e00-\u9fa5]', item_str) and len(item_str) >= 2
                                     and not item_str.isdigit()
                                     and not re.match(r'^[A-Fa-f][+\-]?$', item_str)
                                     and not re.match(r'^\d+(\.\d+)?$', item_str)
                                     and not re.match(r'^[A-Za-z0-9]{3,8}$', item_str)
                                     and not item_str.lower() in ["é€šé", "æŠµå…", "pass", "exempt", "æœªçŸ¥ç§‘ç›®"]
                                     and not any(k in item_str.lower().replace(' ', '').replace('\n', '') for k in all_header_keywords_flat_lower)
                                     )
            if subject_like_cells / total_sample_count >= 0.4:
                found_subject_by_content = True

        if not found_credit_or_gpa_by_content:
            credit_gpa_like_cells = 0
            for item_str in sample_data:
                credit_val, gpa_val = parse_credit_and_gpa(item_str)
                if (0.0 <= credit_val <= 5.0) or \
                   (gpa_val and re.match(r'^[A-Fa-f][+\-]?$', gpa_val)) or \
                   (item_str.lower() in ["é€šé", "æŠµå…", "pass", "exempt"]):
                    credit_gpa_like_cells += 1
            if credit_gpa_like_cells / total_sample_count >= 0.4:
                found_credit_or_gpa_by_content = True

    if found_subject_by_content and found_year_by_content and found_semester_by_content and (found_credit_or_gpa_by_content):
        st.info(f"åµæ¸¬åˆ°ç¬¦åˆæˆç¸¾å–®ç‰¹å¾µçš„è¡¨æ ¼å…§å®¹ (å…§å®¹ç¬¦åˆ: ç§‘ç›®: {found_subject_by_content}, å­¸å¹´: {found_year_by_content}, å­¸æœŸ: {found_semester_by_content}, å­¸åˆ†/GPA: {found_credit_or_gpa_by_content}, é¸èª²ä»£è™Ÿ: {found_course_code_by_content})")
        return True

    return False


def calculate_total_credits(df_list):
    """
    å¾æå–çš„ DataFrames åˆ—è¡¨ä¸­è¨ˆç®—ç¸½å­¸åˆ†ã€‚
    å°‹æ‰¾åŒ…å« 'å­¸åˆ†' æˆ– 'å­¸åˆ†(GPA)' é¡ä¼¼å­—æ¨£çš„æ¬„ä½é€²è¡ŒåŠ ç¸½ã€‚
    è¿”å›ç¸½å­¸åˆ†å’Œè¨ˆç®—å­¸åˆ†çš„ç§‘ç›®åˆ—è¡¨ï¼Œä»¥åŠä¸åŠæ ¼ç§‘ç›®åˆ—è¡¨ã€‚
    """
    total_credits = 0.0
    total_gpa_points = 0.0 # ç”¨æ–¼è¨ˆç®—å¹³å‡GPA
    calculated_courses = []
    failed_courses = []

    if not df_list:
        return total_credits, calculated_courses, failed_courses

    for df_idx, df in enumerate(df_list):
        if df.empty or len(df.columns) < 3:
            st.info(f"è¡¨æ ¼ {df_idx + 1} ç‚ºç©ºæˆ–æ¬„ä½å¤ªå°‘ï¼Œå·²è·³éã€‚")
            continue

        identified_columns = {
            "year": None, "semester": None, "course_code": None,
            "subject": None, "credit": None, "gpa": None
        }

        col_role_scores = collections.defaultdict(lambda: collections.defaultdict(float))

        sample_rows_df = df.head(min(len(df), 20))

        for col_name in df.columns:
            sample_data = sample_rows_df[col_name].apply(normalize_text).tolist()
            total_sample_count = len(sample_data)
            if total_sample_count == 0:
                continue

            norm_col_name_for_header_match = normalize_text(col_name).lower().replace(' ', '').replace('\n', '')

            if any(k in norm_col_name_for_header_match for k in [re.sub(r'[\s\n]+', '', kw.lower()) for kw in year_column_keywords]):
                col_role_scores[col_name]["year"] += 2.0
            if any(k in norm_col_name_for_header_match for k in [re.sub(r'[\s\n]+', '', kw.lower()) for kw in semester_column_keywords]):
                col_role_scores[col_name]["semester"] += 2.0
            if any(k in norm_col_name_for_header_match for k in [re.sub(r'[\s\n]+', '', kw.lower()) for kw in course_code_keywords]):
                col_role_scores[col_name]["course_code"] += 2.0
            if any(k in norm_col_name_for_header_match for k in [re.sub(r'[\s\n]+', '', kw.lower()) for kw in subject_column_keywords]):
                col_role_scores[col_name]["subject"] += 2.0
            if any(k in norm_col_name_for_header_match for k in [re.sub(r'[\s\n]+', '', kw.lower()) for kw in credit_column_keywords]):
                col_role_scores[col_name]["credit"] += 2.0
            if any(k in norm_col_name_for_header_match for k in [re.sub(r'[\s\n]+', '', kw.lower()) for kw in gpa_column_keywords]):
                col_role_scores[col_name]["gpa"] += 2.0

            year_content_score = sum(1 for item_str in sample_data if (item_str.isdigit() and (len(item_str) == 3 or len(item_str) == 4))) / total_sample_count
            semester_content_score = sum(1 for item_str in sample_data if item_str.lower() in ["ä¸Š", "ä¸‹", "æ˜¥", "å¤", "ç§‹", "å†¬", "1", "2", "3", "æ˜¥å­£", "å¤å­£", "ç§‹å­£", "å†¬å­£", "spring", "summer", "fall", "winter"]) / total_sample_count
            course_code_content_score = sum(1 for item_str in sample_data if re.match(r'^[A-Za-z0-9]{3,8}$', item_str) and not item_str.isdigit()) / total_sample_count
            
            credit_gpa_content_score = 0
            for item_str in sample_data:
                credit_val, gpa_val = parse_credit_and_gpa(item_str)
                if (0.0 <= credit_val <= 5.0 and credit_val != 0.0) or \
                   (gpa_val and re.match(r'^[A-Fa-f][+\-]?$', gpa_val)) or \
                   (item_str.lower() in ["é€šé", "æŠµå…", "pass", "exempt"]):
                    credit_gpa_content_score += 1
            credit_gpa_content_score /= total_sample_count

            subject_content_score = sum(1 for item_str in sample_data
                                 if re.search(r'[\u4e00-\u9fa5]', item_str) and len(item_str) >= 2
                                 and not item_str.isdigit()
                                 and not re.match(r'^[A-Fa-f][+\-]?$', item_str)
                                 and not re.match(r'^\d+(\.\d+)?$', item_str)
                                 and not re.match(r'^[A-Za-z0-9]{3,8}$', item_str)
                                 and not item_str.lower() in ["é€šé", "æŠµå…", "pass", "exempt", "æœªçŸ¥ç§‘ç›®"]
                                 and not any(k in item_str.lower().replace(' ', '').replace('\n', '') for k in all_header_keywords_flat_lower)
                                ) / total_sample_count

            col_role_scores[col_name]["year"] += year_content_score
            col_role_scores[col_name]["semester"] += semester_content_score
            col_role_scores[col_name]["course_code"] += course_code_content_score
            col_role_scores[col_name]["credit_gpa_combined"] += credit_gpa_content_score
            col_role_scores[col_name]["subject"] += subject_content_score


        candidate_assignments = []
        for col_name, roles_scores in col_role_scores.items():
            for role, score in roles_scores.items():
                if score > 0:
                    candidate_assignments.append((score, col_name, role))

        candidate_assignments.sort(key=lambda x: (-x[0], df.columns.get_loc(x[1])))

        assigned_cols_names = set()
        for score, col_name, role in candidate_assignments:
            if col_name not in assigned_cols_names:
                if role == "credit_gpa_combined":
                    if identified_columns["credit"] is None and any(k in normalize_text(col_name).lower().replace(' ', '').replace('\n', '') for k in [re.sub(r'[\s\n]+', '', kw.lower()) for kw in credit_column_keywords]):
                        identified_columns["credit"] = col_name
                        assigned_cols_names.add(col_name)
                    elif identified_columns["gpa"] is None and any(k in normalize_text(col_name).lower().replace(' ', '').replace('\n', '') for k in [re.sub(r'[\s\n]+', '', kw.lower()) for kw in gpa_column_keywords]):
                        identified_columns["gpa"] = col_name
                        assigned_cols_names.add(col_name)
                    elif identified_columns["credit"] is None:
                        identified_columns["credit"] = col_name
                        assigned_cols_names.add(col_name)
                    elif identified_columns["gpa"] is None:
                        identified_columns["gpa"] = col_name
                        assigned_cols_names.add(col_name)
                elif identified_columns[role] is None:
                    identified_columns[role] = col_name
                    assigned_cols_names.add(col_name)
        
        found_year_column = identified_columns["year"]
        found_semester_column = identified_columns["semester"]
        found_course_code_column = identified_columns["course_code"]
        found_subject_column = identified_columns["subject"]
        found_credit_column = identified_columns["credit"]
        found_gpa_column = identified_columns["gpa"]

        if found_year_column and found_semester_column and found_subject_column and (found_credit_column or found_gpa_column):
            st.success(f"é é¢ {df_idx + 1} æˆåŠŸè­˜åˆ¥ä»¥ä¸‹é—œéµæ¬„ä½ï¼š")
            st.success(f"  å­¸å¹´æ¬„ä½: '{found_year_column}'")
            st.success(f"  å­¸æœŸæ¬„ä½: '{found_semester_column}'")
            st.success(f"  é¸èª²ä»£è™Ÿæ¬„ä½: '{found_course_code_column if found_course_code_column else 'æœªæ‰¾åˆ°'}'")
            st.success(f"  ç§‘ç›®åç¨±æ¬„ä½: '{found_subject_column}'")
            st.success(f"  å­¸åˆ†æ¬„ä½: '{found_credit_column if found_credit_column else 'æœªæ‰¾åˆ°'}'")
            st.success(f"  GPA æ¬„ä½: '{found_gpa_column if found_gpa_column else 'æœªæ‰¾åˆ°'}'")

            try:
                for row_idx, row in df.iterrows():
                    st.info(f"--- è™•ç†è¡¨æ ¼ {df_idx + 1}, ç¬¬ {row_idx + 1} è¡Œ ---")
                    row_content_normalized = [normalize_text(str(cell)) for cell in row.tolist()]
                    st.info(f"åŸå§‹è³‡æ–™åˆ—å…§å®¹ (æ¨™æº–åŒ–å¾Œ): {row_content_normalized}")

                    is_header_row_content = False
                    header_keyword_matches = 0
                    for cell_val in row_content_normalized:
                        if cell_val.lower().replace(' ', '').replace('\n', '') in all_header_keywords_flat_lower:
                            header_keyword_matches += 1

                    if (header_keyword_matches >= len(row_content_normalized) / 2 and header_keyword_matches >= 3) or \
                       (len(row_content_normalized) > 0 and row_content_normalized[0] == "" and header_keyword_matches >= 3):
                        st.info("è©²è¡Œè¢«åˆ¤æ–·ç‚ºæ¨™é ­è¡Œï¼Œå·²è·³éã€‚")
                        continue

                    if all(cell == "" for cell in row_content_normalized) or \
                       any("æœ¬è¡¨åƒ…ä¾›æŸ¥è©¢" in cell or "å­¸è™Ÿ" in cell or "å‹ä½œ" in cell or "é«”è‚²å®¤" in cell or "ç•¢æ¥­é–€æª»" in cell or "ç¶²ç«™" in cell or "http" in cell for cell in row_content_normalized):
                        st.info("è©²è¡Œè¢«åˆ¤æ–·ç‚ºç©ºè¡Œã€è¡Œæ”¿æ€§æ–‡å­—æˆ–é è…³ï¼Œå·²è·³éã€‚")
                        continue

                    extracted_credit = 0.0
                    extracted_gpa = ""
                    course_name = "æœªçŸ¥ç§‘ç›®"
                    acad_year = ""
                    semester = ""
                    course_code = ""

                    if found_year_column and found_year_column in row and pd.notna(row[found_year_column]):
                        temp_year = normalize_text(row[found_year_column])
                        year_match = re.search(r'(\d{3,4})', temp_year)
                        if year_match:
                            acad_year = year_match.group(1)

                    if found_semester_column and found_semester_column in row and pd.notna(row[found_semester_column]):
                        temp_sem = normalize_text(row[found_semester_column])
                        sem_match = re.search(r'(ä¸Š|ä¸‹|æ˜¥|å¤|ç§‹|å†¬|1|2|3|æ˜¥å­£|å¤å­£|ç§‹å­£|å†¬å­£|spring|summer|fall|winter)', temp_sem, re.IGNORECASE)
                        if sem_match:
                            semester = sem_match.group(1)

                    if not acad_year and not semester:
                        for col_idx in range(min(len(df.columns), 3)):
                            col_name = df.columns[col_idx]
                            if col_name in row and pd.notna(row[col_name]):
                                col_content = normalize_text(row[col_name])
                                year_match = re.search(r'(\d{3,4})', col_content)
                                sem_match = re.search(r'(ä¸Š|ä¸‹|æ˜¥|å¤|ç§‹|å†¬|1|2|3|æ˜¥å­£|å¤å­£|ç§‹å­£|å†¬å­£|spring|summer|fall|winter)', col_content, re.IGNORECASE)
                                if year_match and not acad_year:
                                    acad_year = year_match.group(1)
                                if sem_match and not semester:
                                    semester = sem_match.group(1)
                                if acad_year and semester:
                                    break

                    if found_course_code_column and found_course_code_column in row and pd.notna(row[found_course_code_column]):
                        temp_code = normalize_text(row[found_course_code_column])
                        if re.match(r'^[A-Za-z0-9]{3,8}$', temp_code):
                            course_code = temp_code

                    if found_credit_column and found_credit_column in row and pd.notna(row[found_credit_column]):
                        temp_credit, _ = parse_credit_and_gpa(row[found_credit_column])
                        if temp_credit > 0 or normalize_text(row[found_credit_column]).lower() in ["é€šé", "æŠµå…", "pass", "exempt"]:
                             extracted_credit = temp_credit

                    if found_gpa_column and found_gpa_column in row and pd.notna(row[found_gpa_column]):
                        _, temp_gpa = parse_credit_and_gpa(row[found_gpa_column])
                        if temp_gpa:
                            extracted_gpa = temp_gpa.upper()

                    if (extracted_credit == 0.0 and not extracted_gpa):
                        if found_credit_column and found_credit_column in row and pd.notna(row[found_credit_column]):
                            combined_val = normalize_text(row[found_credit_column])
                            temp_credit, temp_gpa = parse_credit_and_gpa(combined_val)
                            if temp_credit > 0:
                                extracted_credit = temp_credit
                            if temp_gpa and not extracted_gpa:
                                extracted_gpa = temp_gpa.upper()
                        
                        if (extracted_credit == 0.0 and not extracted_gpa) and found_gpa_column and found_gpa_column in row and pd.notna(row[found_gpa_column]):
                            combined_val = normalize_text(row[found_gpa_column])
                            temp_credit, temp_gpa = parse_credit_and_gpa(combined_val)
                            if temp_credit > 0:
                                extracted_credit = temp_credit
                            if temp_gpa and not extracted_gpa:
                                extracted_gpa = temp_gpa.upper()

                    if found_subject_column and found_subject_column in row and pd.notna(row[found_subject_column]):
                        temp_name = normalize_text(row[found_subject_column])
                        if len(temp_name) >= 2 and re.search(r'[\u4e00-\u9fa5]', temp_name) and \
                           not temp_name.isdigit() and not re.match(r'^[A-Fa-f][+\-]?$', temp_name) and \
                           not re.match(r'^\d+(\.\d+)?$', temp_name) and \
                           not re.match(r'^[A-Za-z0-9]{3,8}$', temp_name) and \
                           not temp_name.lower() in ["é€šé", "æŠµå…", "pass", "exempt", "æœªçŸ¥ç§‘ç›®"] and \
                           not any(re.sub(r'[\s\n]+', '', kw.lower()) in re.sub(r'[\s\n]+', '', temp_name.lower()) for kw in all_header_keywords_flat_lower) and \
                           not any(re.search(pattern, temp_name) for pattern in ["å­¸è™Ÿ", "æœ¬è¡¨", "è¨»èª²çµ„", "å¹´ç´š", "ç­ç´š", "ç³»åˆ¥", "ç•¢æ¥­é–€æª»", "é«”è‚²å¸¸è­˜", "å­¸è™Ÿ", "å§“å", "ç­ç´š", "ç³»åˆ¥"]):
                            course_name = temp_name
                        else:
                            st.info(f"ç§‘ç›®åç¨±æ¬„ä½ '{found_subject_column}' å…§å®¹ '{temp_name}' ä¸ç¬¦åˆèª²ç¨‹åç¨±æ¨¡å¼ã€‚å°‡å˜—è©¦ç›¸é„°æ¬„ä½ã€‚")

                    if course_name == "æœªçŸ¥ç§‘ç›®" and found_course_code_column and found_course_code_column in row and pd.notna(row[found_course_code_column]):
                        current_col_idx = df.columns.get_loc(found_course_code_column)
                        if current_col_idx < len(df.columns) -1:
                            next_col_name = df.columns[current_col_idx + 1]
                            if next_col_name in row and pd.notna(row[next_col_name]):
                                temp_name_next = normalize_text(row[next_col_name])
                                if len(temp_name_next) >= 2 and re.search(r'[\u4e00-\u9fa5]', temp_name_next) and \
                                   not temp_name_next.isdigit() and not re.match(r'^[A-Fa-f][+\-]?$', temp_name_next) and \
                                   not re.match(r'^\d+(\.\d+)?$', temp_name_next) and \
                                   not re.match(r'^[A-Za-z0-9]{3,8}$', temp_name_next) and \
                                   not any(re.sub(r'[\s\n]+', '', kw.lower()) in re.sub(r'[\s\n]+', '', temp_name_next.lower()) for kw in all_header_keywords_flat_lower):
                                    course_name = temp_name_next
                                    st.info(f"å¾é¸èª²ä»£è™Ÿå³å´æ¬„ä½ '{next_col_name}' æ‰¾åˆ°ç§‘ç›®åç¨±: '{course_name}'")

                    is_failing_grade = False
                    if extracted_gpa:
                        gpa_clean = re.sub(r'[+\-]', '', extracted_gpa).upper()
                        if gpa_clean in [g.upper() for g in failing_grades] or \
                           (gpa_clean.replace('.', '', 1).isdigit() and float(gpa_clean) < 60):
                            is_failing_grade = True
                    is_passed_or_exempt_grade = False
                    if "é€šé" in extracted_gpa.lower() or "æŠµå…" in extracted_gpa.lower() or \
                       "pass" in extracted_gpa.lower() or "exempt" in extracted_gpa.lower() or \
                       "é€šé" in normalize_text(row.to_string()).lower() or \
                       "æŠµå…" in normalize_text(row.to_string()).lower():
                        is_passed_or_exempt_grade = True
                        if extracted_credit == 0.0:
                            extracted_credit = 0.0

                    st.info(f"è§£æçµæœ: å­¸å¹´='{acad_year}', å­¸æœŸ='{semester}', é¸èª²ä»£è™Ÿ='{course_code}', ç§‘ç›®åç¨±='{course_name}', å­¸åˆ†='{extracted_credit}', GPA='{extracted_gpa}', æ˜¯å¦ä¸åŠæ ¼='{is_failing_grade}', æ˜¯å¦é€šé/æŠµå…='{is_passed_or_exempt_grade}'")


                    if (course_name == "æœªçŸ¥ç§‘ç›®" or not acad_year or not semester) and extracted_credit == 0.0 and not extracted_gpa and not is_passed_or_exempt_grade:
                        st.info("è©²è¡Œæ²’æœ‰è­˜åˆ¥åˆ°æœ‰æ•ˆçš„å­¸å¹´/å­¸æœŸ/ç§‘ç›®åç¨±/å­¸åˆ†/æˆç¸¾ï¼Œä¸”éé€šé/æŠµå…èª²ç¨‹ï¼Œå·²è·³éã€‚")
                        continue

                    if is_failing_grade:
                        failed_courses.append({
                            "å­¸å¹´åº¦": acad_year,
                            "å­¸æœŸ": semester,
                            "ç§‘ç›®åç¨±": course_name,
                            "å­¸åˆ†": extracted_credit,
                            "GPA": extracted_gpa,
                            "ä¾†æºè¡¨æ ¼": df_idx + 1
                        })
                        st.warning(f"åµæ¸¬åˆ°ä¸åŠæ ¼ç§‘ç›®: {course_name} (å­¸åˆ†: {extracted_credit}, GPA: {extracted_gpa})ï¼Œæœªè¨ˆå…¥ç¸½å­¸åˆ†ã€‚")
                    elif extracted_credit > 0 or is_passed_or_exempt_grade:
                        total_credits += extracted_credit
                        course_gpa_value = 0.0
                        if extracted_gpa in grade_to_gpa:
                            course_gpa_value = grade_to_gpa[extracted_gpa]
                        elif extracted_gpa.replace('.', '', 1).isdigit(): # å¦‚æœæ˜¯æ•¸å­—æˆç¸¾
                             try:
                                # è½‰æ›ç™¾åˆ†åˆ¶æˆç¸¾ç‚º 4.0 GPA åˆ¶ (ç¯„ä¾‹ï¼šå‡è¨­ 60 åŠæ ¼ï¼Œ90+ ç‚º A)
                                score = float(extracted_gpa)
                                if score >= 90: course_gpa_value = 4.0
                                elif score >= 80: course_gpa_value = 3.0
                                elif score >= 70: course_gpa_value = 2.0
                                elif score >= 60: course_gpa_value = 1.0
                                else: course_gpa_value = 0.0
                             except ValueError:
                                 pass # éæ•¸å­—ï¼Œå¿½ç•¥

                        total_gpa_points += course_gpa_value * extracted_credit

                        calculated_courses.append({
                            "å­¸å¹´åº¦": acad_year,
                            "å­¸æœŸ": semester,
                            "ç§‘ç›®åç¨±": course_name,
                            "å­¸åˆ†": extracted_credit,
                            "GPA": extracted_gpa,
                            "ä¾†æºè¡¨æ ¼": df_idx + 1
                        })
                        st.success(f"æˆåŠŸè™•ç†èª²ç¨‹: {course_name} (å­¸åˆ†: {extracted_credit}, GPA: {extracted_gpa})ï¼Œå­¸åˆ†å·²è¨ˆå…¥ã€‚")
                    else:
                        st.info(f"è©²è¡Œæœªè¨ˆå…¥å­¸åˆ†ï¼Œå­¸åˆ†: {extracted_credit}, GPA: {extracted_gpa}, æ˜¯å¦é€šé/æŠµå…: {is_passed_or_exempt_grade}")


            except Exception as e:
                st.error(f"è¡¨æ ¼ {df_idx + 1} çš„å­¸åˆ†è¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: `{e}`ã€‚è©²è¡¨æ ¼çš„å­¸åˆ†å¯èƒ½ç„¡æ³•è¨ˆå…¥ç¸½æ•¸ã€‚è«‹æª¢æŸ¥å­¸åˆ†å’ŒGPAæ¬„ä½æ•¸æ“šæ˜¯å¦æ­£ç¢ºã€‚")
        else:
            st.warning(f"é é¢ {df_idx + 1} çš„è¡¨æ ¼æœªèƒ½è­˜åˆ¥ç‚ºæˆç¸¾å–®è¡¨æ ¼ (ç¼ºå°‘å¿…è¦çš„ å­¸å¹´/å­¸æœŸ/ç§‘ç›®åç¨±/å­¸åˆ†/GPA æ¬„ä½)ã€‚å·²åµæ¸¬åˆ°çš„æ¬„ä½: å­¸å¹´='{found_year_column if found_year_column else 'ç„¡'}', å­¸æœŸ='{found_semester_column if found_semester_column else 'ç„¡'}', é¸èª²ä»£è™Ÿ='{found_course_code_column if found_course_code_column else 'ç„¡'}', ç§‘ç›®åç¨±='{found_subject_column if found_subject_column else 'ç„¡'}', å­¸åˆ†='{found_credit_column if found_credit_column else 'ç„¡'}', GPA='{found_gpa_column if found_gpa_column else 'ç„¡'}'")

    return total_credits, total_gpa_points, calculated_courses, failed_courses


def process_pdf_file_with_pdfplumber(uploaded_file):
    """
    ä½¿ç”¨ pdfplumber è™•ç†ä¸Šå‚³çš„ PDF æª”æ¡ˆï¼Œæå–è¡¨æ ¼ã€‚
    è¿”å›æå–çš„ DataFrames åˆ—è¡¨å’Œä¸€å€‹å¸ƒæ—å€¼è¡¨ç¤ºæ˜¯å¦æˆåŠŸæå–åˆ°è¡¨æ ¼ã€‚
    """
    all_grades_data_dfs = []
    pdfplumber_success = False

    try:
        with pdfplumber.open(uploaded_file) as pdf:
            for page_num, page in enumerate(pdf.pages):
                current_page = page

                table_settings_1 = {
                    "vertical_strategy": "text", "horizontal_strategy": "text",
                    "snap_tolerance": 8, "join_tolerance": 8, "edge_min_length": 3,
                    "text_tolerance": 5, "min_words_vertical": 1, "min_words_horizontal": 1,
                }
                table_settings_2 = {
                    "vertical_strategy": "text", "horizontal_strategy": "text",
                    "snap_tolerance": 15, "join_tolerance": 15, "text_tolerance": 10,
                    "edge_min_length": 3, "min_words_vertical": 1, "min_words_horizontal": 1,
                }
                table_settings_3 = {
                    "vertical_strategy": "lines", "horizontal_strategy": "lines",
                    "snap_tolerance": 3, "join_tolerance": 3, "edge_min_length": 3,
                    "text_tolerance": 3, "min_words_vertical": 1, "min_words_horizontal": 1,
                }

                tables = []
                try:
                    tables = current_page.extract_tables(table_settings_1)
                    if tables: st.info(f"é é¢ {page_num + 1} ä½¿ç”¨è¨­å®š1æå–åˆ°è¡¨æ ¼ã€‚")
                except Exception as e: st.warning(f"é é¢ {page_num + 1} ä½¿ç”¨è¨­å®š1æå–è¡¨æ ¼å¤±æ•—: {e}")

                if not tables:
                    try:
                        st.info(f"é é¢ {page_num + 1} æœªåµæ¸¬åˆ°è¡¨æ ¼ï¼Œå˜—è©¦ä½¿ç”¨æ›´ç©æ¥µçš„æ–‡å­—è¨­å®š...")
                        tables = current_page.extract_tables(table_settings_2)
                        if tables: st.info(f"é é¢ {page_num + 1} ä½¿ç”¨è¨­å®š2æå–åˆ°è¡¨æ ¼ã€‚")
                    except Exception as e: st.warning(f"é é¢ {page_num + 1} ä½¿ç”¨è¨­å®š2æå–è¡¨æ ¼å¤±æ•—: {e}")

                if not tables:
                    try:
                        st.info(f"é é¢ {page_num + 1} ä»æœªåµæ¸¬åˆ°è¡¨æ ¼ï¼Œå˜—è©¦ä½¿ç”¨åŸºæ–¼ç·šæ¢çš„è¨­å®š...")
                        tables = current_page.extract_tables(table_settings_3)
                        if tables: st.info(f"é é¢ {page_num + 1} ä½¿ç”¨è¨­å®š3æå–åˆ°è¡¨æ ¼ã€‚")
                    except Exception as e: st.warning(f"é é¢ {page_num + 1} ä½¿ç”¨è¨­å®š3æå–è¡¨æ ¼å¤±æ•—: {e}")

                if not tables:
                    st.warning(f"é é¢ **{page_num + 1}** æœªåµæ¸¬åˆ°è¡¨æ ¼ (pdfplumber)ã€‚é€™å¯èƒ½æ˜¯ç”±æ–¼ PDF æ ¼å¼è¤‡é›œæˆ–è¡¨æ ¼æå–è¨­å®šä¸é©ç”¨ã€‚")
                    continue

                for table_idx, table in enumerate(tables):
                    processed_table = []
                    for row in table:
                        normalized_row = [normalize_text(cell) for cell in row]
                        if any(cell.strip() != "" for cell in normalized_row):
                            processed_table.append(normalized_row)

                    if not processed_table:
                        st.info(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ **{table_idx + 1}** æå–å¾Œç‚ºç©ºæˆ–å…¨ç‚ºç©ºç™½è¡Œã€‚")
                        continue

                    df_table_to_add = None

                    if len(processed_table) > 1:
                        potential_header_row = processed_table[0]
                        max_cols_temp = max(len(cell_list) for cell_list in processed_table)
                        padded_header_row = potential_header_row + [''] * (max_cols_temp - len(potential_header_row))
                        temp_unique_columns = make_unique_columns(padded_header_row)

                        header_keyword_count = sum(1 for cell in padded_header_row if normalize_text(cell).lower().replace(' ', '').replace('\n', '') in all_header_keywords_flat_lower)
                        
                        if header_keyword_count >= 3:
                            temp_data_rows = processed_table[1:]
                            num_cols_for_df = len(temp_unique_columns)
                            cleaned_temp_data_rows = []
                            for row_data in temp_data_rows:
                                if len(row_data) > num_cols_for_df:
                                    cleaned_temp_data_rows.append(row_data[:num_cols_for_df])
                                elif len(row_data) < num_cols_for_df:
                                    cleaned_temp_data_rows.append(row_data + [''] * (num_cols_for_df - len(row_data)))
                                else:
                                    cleaned_temp_data_rows.append(row_data)

                            if cleaned_temp_data_rows:
                                try:
                                    df_table_with_assumed_header = pd.DataFrame(cleaned_temp_data_rows, columns=temp_unique_columns)
                                    if is_grades_table(df_table_with_assumed_header):
                                        df_table_to_add = df_table_with_assumed_header
                                        st.success(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} å·²è­˜åˆ¥ç‚ºæˆç¸¾å–®è¡¨æ ¼ (å¸¶æœ‰åµæ¸¬åˆ°çš„æ¨™é ­)ã€‚")
                                except Exception as e_df_temp:
                                    st.warning(f"é é¢ {page_num + 1} è¡¨æ ¼ {table_idx + 1} å˜—è©¦ç”¨ç¬¬ä¸€è¡Œä½œæ¨™é ­è½‰æ›ç‚º DataFrame æ™‚ç™¼ç”ŸéŒ¯èª¤: `{e_df_temp}`ã€‚")
                            else:
                                st.info(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} ç¬¬ä¸€è¡Œè¢«è­˜åˆ¥ç‚ºæ¨™é ­ä½†ç„¡æ•¸æ“šè¡Œã€‚")

                    if df_table_to_add is None:
                        max_cols = max(len(row_data) for row_data in processed_table)
                        generic_columns = make_unique_columns([f"Column_{i+1}" for i in range(max_cols)])

                        cleaned_all_rows_data = []
                        for row_data in processed_table:
                            if len(row_data) > max_cols:
                                cleaned_all_rows_data.append(row_data[:max_cols])
                            elif len(row_data) < max_cols:
                                cleaned_all_rows_data.append(row_data + [''] * (max_cols - len(row_data)))
                            else:
                                cleaned_all_rows_data.append(row_data)

                        if cleaned_all_rows_data:
                            try:
                                df_table_all_data = pd.DataFrame(cleaned_all_rows_data, columns=generic_columns)
                                if is_grades_table(df_table_all_data):
                                    df_table_to_add = df_table_all_data
                                    st.success(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} å·²è­˜åˆ¥ç‚ºæˆç¸¾å–®è¡¨æ ¼ (æ‰€æœ‰è¡Œçš†ç‚ºæ•¸æ“šï¼Œä½¿ç”¨é€šç”¨æ¨™é ­)ã€‚")
                                else:
                                    st.info(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ {table_idx + 1} æœªèƒ½è­˜åˆ¥ç‚ºæˆç¸¾å–®è¡¨æ ¼ï¼Œå·²è·³éã€‚")
                            except Exception as e_df_all:
                                st.error(f"é é¢ {page_num + 1} è¡¨æ ¼ {table_idx + 1} å˜—è©¦ç”¨æ‰€æœ‰è¡Œä½œæ•¸æ“šè½‰æ›ç‚º DataFrame æ™‚ç™¼ç”ŸéŒ¯èª¤: `{e_df_all}`")
                        else:
                            st.info(f"é é¢ {page_num + 1} çš„è¡¨æ ¼ **{table_idx + 1}** æ²’æœ‰æœ‰æ•ˆæ•¸æ“šè¡Œã€‚")

                    if df_table_to_add is not None:
                        all_grades_data_dfs.append(df_table_to_add)
                        pdfplumber_success = True

    except pdfplumber.PDFSyntaxError as e_pdf_syntax:
        st.error(f"è™•ç† PDF èªæ³•æ™‚ç™¼ç”ŸéŒ¯èª¤: `{e_pdf_syntax}`ã€‚æª”æ¡ˆå¯èƒ½å·²æå£æˆ–æ ¼å¼ä¸æ­£ç¢ºï¼Œå°‡å˜—è©¦ OCRã€‚")
        pdfplumber_success = False # å³ä½¿å ±éŒ¯ï¼Œä¹Ÿæ¨™è¨˜ç‚º pdfplumber å¤±æ•—
    except Exception as e:
        st.error(f"è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”Ÿä¸€èˆ¬éŒ¯èª¤: `{e}`ï¼Œå°‡å˜—è©¦ OCRã€‚")
        st.error("è«‹ç¢ºèªæ‚¨çš„ PDF æ ¼å¼æ˜¯å¦ç‚ºæ¸…æ™°çš„è¡¨æ ¼ã€‚")
        pdfplumber_success = False

    return all_grades_data_dfs, pdfplumber_success

def process_pdf_file_with_ocr(uploaded_file):
    """
    ä½¿ç”¨ OCR (img2table + Tesseract) è™•ç†åœ–ç‰‡ PDF æª”æ¡ˆï¼Œæå–è¡¨æ ¼ã€‚
    """
    all_grades_data_dfs = []
    
    st.info("å•Ÿç”¨ OCR (img2table + Tesseract) æå–åœ–ç‰‡ PDF ä¸­çš„è¡¨æ ¼ã€‚é€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ã€‚")
    try:
        # åˆå§‹åŒ– Tesseract OCR
        # è«‹ç¢ºä¿ Tesseract OCR å·²ç¶“å®‰è£ä¸¦åœ¨ç³»çµ± PATH ä¸­
        # å¦‚æœ Tesseract ä¸åœ¨ PATH ä¸­ï¼Œä½ éœ€è¦æŒ‡å®šå…¶å®‰è£è·¯å¾‘ï¼Œä¾‹å¦‚:
        # tesseract_cmd_path = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Windows ç¯„ä¾‹
        # ocr = TesseractOCR(lang="chi_tra", tesseract_cmd=tesseract_cmd_path) 
        # é€™è£¡å‡è¨­ Tesseract å·²åœ¨ PATH ä¸­ï¼Œä¸¦ä½¿ç”¨ç¹é«”ä¸­æ–‡èªè¨€åŒ…
        ocr = TesseractOCR(lang="chi_tra") 

        # ä½¿ç”¨ img2table æå– PDF ä¸­çš„è¡¨æ ¼
        pdf_bytes = io.BytesIO(uploaded_file.getvalue())
        img_pdf = Img2TablePDF(src=pdf_bytes, detect_rotation=True)
        tables_img2table = img_pdf.extract_tables(ocr=ocr)

        if tables_img2table:
            st.success(f"ä½¿ç”¨ OCR (img2table) æˆåŠŸå¾ {len(tables_img2table)} å€‹è¡¨æ ¼ä¸­æå–æ•¸æ“šï¼")
            
            for table in tables_img2table:
                # img2table çš„ table.content æ˜¯ä¸€å€‹ pandas DataFrame
                df_ocr = table.content.copy()
                # å†æ¬¡ä½¿ç”¨ normalize_text è™•ç† OCR çµæœï¼Œç¢ºä¿ä¸€è‡´æ€§
                for col in df_ocr.columns:
                    df_ocr[col] = df_ocr[col].apply(normalize_text)
                
                # OCR çµæœçš„æ¬„ä½åç¨±å¯èƒ½ä¸è¦ç¯„ï¼Œéœ€è¦å˜—è©¦é‡æ–°åŒ¹é…
                # é€™è£¡å‡è¨­ OCR è¾¨è­˜å‡ºçš„æ¬„ä½é †åºå¤§è‡´ä¸è®Š
                if not df_ocr.empty and is_grades_table(df_ocr):
                    # é‡æ–°æ˜ å°„æ¬„ä½åç¨±
                    mapped_df = pd.DataFrame()
                    col_map_flexible_ocr = {
                        'å­¸å¹´åº¦': ['å­¸å¹´åº¦', 'å­¸å¹´', 'Year'],
                        'å­¸æœŸ': ['å­¸æœŸ', 'Semester'],
                        'é¸èª²ä»£è™Ÿ': ['é¸èª²ä»£è™Ÿ', 'èª²ç¨‹ä»£ç¢¼', 'Course Code'],
                        'ç§‘ç›®åç¨±': ['ç§‘ç›®åç¨±', 'èª²ç¨‹åç¨±', 'Subject Name', 'Course Name'],
                        'å­¸åˆ†': ['å­¸åˆ†', 'å­¸åˆ†æ•¸', 'Credits', 'Credit'],
                        'GPA': ['GPA', 'æˆç¸¾', 'Grade']
                    }
                    
                    for target_col, possible_names in col_map_flexible_ocr.items():
                        found_col = None
                        for name_variant in possible_names:
                            if name_variant in df_ocr.columns:
                                found_col = name_variant
                                break
                            # å˜—è©¦æ¨™æº–åŒ– df_ocr çš„åˆ—åå¾Œå†åŒ¹é…
                            for df_col in df_ocr.columns:
                                if normalize_text(df_col).lower().replace(' ', '').replace('\n', '') == normalize_text(name_variant).lower().replace(' ', '').replace('\n', ''):
                                    found_col = df_col
                                    break
                            if found_col: break

                        if found_col:
                            mapped_df[target_col] = df_ocr[found_col]
                        else:
                            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ï¼Œæ·»åŠ ä¸€å€‹ç©ºåˆ—ï¼Œé¿å… KeyError
                            mapped_df[target_col] = "" 
                            
                    all_grades_data_dfs.append(mapped_df)
                else:
                    st.warning(f"OCR æå–åˆ°çš„è¡¨æ ¼ {len(all_grades_data_dfs) + 1} æœªèƒ½è­˜åˆ¥ç‚ºæˆç¸¾å–®è¡¨æ ¼ã€‚")

        else:
            st.error("OCR (img2table) æœªèƒ½å¾ PDF ä¸­æå–åˆ°ä»»ä½•è¡¨æ ¼æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF å…§å®¹æ˜¯å¦ç‚ºæ¸…æ™°çš„è¡¨æ ¼åœ–ç‰‡ã€‚")

    except Exception as e:
        st.error(f"OCR è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}ã€‚è«‹ç¢ºèªæ‚¨çš„ Tesseract OCR å®‰è£æ­£ç¢ºï¼Œä¸¦å·²å®‰è£ç¹é«”ä¸­æ–‡èªè¨€åŒ…ã€‚")
        st.info("éŒ¯èª¤æç¤ºï¼šå¦‚æœé‡åˆ° 'tesseract is not installed or not in your PATH' éŒ¯èª¤ï¼Œè«‹ç¢ºä¿æ‚¨å·²å®‰è£ Tesseract OCR ä¸¦å°‡å…¶æ·»åŠ åˆ°ç³»çµ±ç’°å¢ƒè®Šæ•¸ PATH ä¸­ã€‚")

    return all_grades_data_dfs


# --- Streamlit æ‡‰ç”¨ä¸»é«” ---
def main():
    st.set_page_config(page_title="PDF æˆç¸¾å–®å­¸åˆ†è¨ˆç®—å·¥å…·", layout="wide")
    st.title("ğŸ“„ PDF æˆç¸¾å–®å­¸åˆ†è¨ˆç®—å·¥å…·")

    st.write("è«‹ä¸Šå‚³æ‚¨çš„ PDF æˆç¸¾å–®æª”æ¡ˆï¼Œå·¥å…·å°‡å˜—è©¦æå–å…¶ä¸­çš„è¡¨æ ¼æ•¸æ“šä¸¦è¨ˆç®—ç¸½å­¸åˆ†ã€‚")
    st.write("æ‚¨ä¹Ÿå¯ä»¥è¼¸å…¥ç›®æ¨™å­¸åˆ†ï¼ŒæŸ¥çœ‹é‚„å·®å¤šå°‘å­¸åˆ†ã€‚")

    uploaded_file = st.file_uploader("é¸æ“‡ä¸€å€‹ PDF æª”æ¡ˆ", type="pdf")

    if uploaded_file is not None:
        st.success(f"å·²ä¸Šå‚³æª”æ¡ˆ: **{uploaded_file.name}**")
        
        extracted_dfs = []
        pdfplumber_extracted_successfully = False

        with st.spinner("æ­£åœ¨å˜—è©¦ä½¿ç”¨ pdfplumber è™•ç† PDF..."):
            extracted_dfs, pdfplumber_extracted_successfully = process_pdf_file_with_pdfplumber(uploaded_file)

        if not pdfplumber_extracted_successfully or not extracted_dfs:
            st.warning("pdfplumber æœªèƒ½æˆåŠŸæå–è¡¨æ ¼ï¼Œå¯èƒ½æ˜¯åœ–ç‰‡ PDF æˆ–è¡¨æ ¼çµæ§‹è¤‡é›œã€‚å˜—è©¦ä½¿ç”¨ OCR é€²è¡Œåœ–ç‰‡åˆ†æ...")
            with st.spinner("æ­£åœ¨ä½¿ç”¨ OCR è™•ç† PDF (é€™å¯èƒ½éœ€è¦æ›´é•·çš„æ™‚é–“)..."):
                extracted_dfs = process_pdf_file_with_ocr(uploaded_file)

        if extracted_dfs:
            st.markdown("---")
            st.markdown("## âš™ï¸ åµéŒ¯è³‡è¨Š (Debug Info)")
            st.info("ä»¥ä¸‹æ˜¯ç¨‹å¼ç¢¼è™•ç†æ¯è¡Œæ•¸æ“šçš„è©³ç´°éç¨‹ï¼Œå¹«åŠ©æ‚¨ç†è§£å­¸åˆ†è¨ˆç®—å’Œèª²ç¨‹è­˜åˆ¥çš„ç‹€æ³ã€‚")
            st.info("æ‚¨ä¸Šå‚³çš„åŸå§‹è¡¨æ ¼å…§å®¹å°‡æœƒé¡¯ç¤ºï¼Œä»¥åŠç¨‹å¼ç¢¼å¦‚ä½•è§£æå„å€‹æ¬„ä½ã€‚")
            st.info("å¦‚æœæ‚¨ç™¼ç¾æœ‰èª¤ï¼Œè«‹æ ¹æ“šé€™äº›è³‡è¨Šå‘ŠçŸ¥æˆ‘å…·é«”æ˜¯å“ªå€‹è¡¨æ ¼çš„å“ªä¸€è¡Œã€å“ªå€‹æ¬„ä½æœ‰å•é¡Œã€‚")
            st.info("--- åµéŒ¯è¨Šæ¯çµæŸ ---")

            total_credits, total_gpa_points, calculated_courses, failed_courses = calculate_total_credits(extracted_dfs)

            st.markdown("---")
            st.markdown("## âœ… æŸ¥è©¢çµæœ")
            st.markdown(f"ç›®å‰ç¸½å­¸åˆ†: <span style='color:green; font-size: 24px;'>**{total_credits:.2f}**</span>", unsafe_allow_html=True)

            if total_credits > 0:
                average_gpa = total_gpa_points / total_credits
                st.markdown(f"ç›®å‰å¹³å‡ GPA: <span style='color:blue; font-size: 20px;'>**{average_gpa:.2f}**</span>", unsafe_allow_html=True)
            else:
                st.info("æ²’æœ‰è¶³å¤ çš„åŠæ ¼å­¸åˆ†ä¾†è¨ˆç®—å¹³å‡ GPAã€‚")

            target_credits = st.number_input("è¼¸å…¥æ‚¨çš„ç›®æ¨™å­¸åˆ† (ä¾‹å¦‚ï¼š128)", min_value=0.0, value=128.0, step=1.0,
                                            help="æ‚¨å¯ä»¥è¨­å®šä¸€å€‹ç•¢æ¥­å­¸åˆ†ç›®æ¨™ï¼Œå·¥å…·æœƒå¹«æ‚¨è¨ˆç®—é‚„å·®å¤šå°‘å­¸åˆ†ã€‚")

            credit_difference = target_credits - total_credits
            if credit_difference > 0:
                st.write(f"è·é›¢ç•¢æ¥­æ‰€éœ€å­¸åˆ† (å…±{target_credits:.0f}å­¸åˆ†) é‚„å·® **{credit_difference:.2f}**")
            elif credit_difference < 0:
                st.write(f"å·²è¶…è¶Šç•¢æ¥­å­¸åˆ† (å…±{target_credits:.0f}å­¸åˆ†) **{abs(credit_difference):.2f}**")
            else:
                st.write(f"å·²é”åˆ°ç•¢æ¥­æ‰€éœ€å­¸åˆ† (å…±{target_credits:.0f}å­¸åˆ†) **0.00**")


            st.markdown("---")
            st.markdown("### ğŸ“š é€šéçš„èª²ç¨‹åˆ—è¡¨")
            if calculated_courses:
                courses_df = pd.DataFrame(calculated_courses)
                display_cols = ['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA']
                # å¦‚æœæœ‰é¸èª²ä»£è™Ÿï¼Œä¹Ÿé¡¯ç¤º
                if 'é¸èª²ä»£è™Ÿ' in courses_df.columns:
                    display_cols.insert(2, 'é¸èª²ä»£è™Ÿ')

                final_display_cols = [col for col in display_cols if col in courses_df.columns]
                st.dataframe(courses_df[final_display_cols], height=300, use_container_width=True)
            else:
                st.info("æ²’æœ‰æ‰¾åˆ°å¯ä»¥è¨ˆç®—å­¸åˆ†çš„ç§‘ç›®ã€‚")

            if failed_courses:
                st.markdown("---")
                st.markdown("### âš ï¸ ä¸åŠæ ¼çš„èª²ç¨‹åˆ—è¡¨")
                failed_df = pd.DataFrame(failed_courses)
                display_failed_cols = ['å­¸å¹´åº¦', 'å­¸æœŸ', 'ç§‘ç›®åç¨±', 'å­¸åˆ†', 'GPA', 'ä¾†æºè¡¨æ ¼']
                # å¦‚æœæœ‰é¸èª²ä»£è™Ÿï¼Œä¹Ÿé¡¯ç¤º
                if 'é¸èª²ä»£è™Ÿ' in failed_df.columns:
                    display_failed_cols.insert(2, 'é¸èª²ä»£è™Ÿ')

                final_display_failed_cols = [col for col in display_failed_cols if col in failed_df.columns]
                st.dataframe(failed_df[final_display_failed_cols], height=200, use_container_width=True)
                st.info("é€™äº›ç§‘ç›®å› æˆç¸¾ä¸åŠæ ¼ ('D', 'E', 'F' ç­‰) è€Œæœªè¨ˆå…¥ç¸½å­¸åˆ†ã€‚")

            if calculated_courses or failed_courses:
                if calculated_courses:
                    courses_df_export = pd.DataFrame(calculated_courses)
                    csv_data_passed = courses_df_export.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ä¸‹è¼‰é€šéçš„ç§‘ç›®åˆ—è¡¨ç‚º CSV",
                        data=csv_data_passed,
                        file_name=f"{uploaded_file.name.replace('.pdf', '')}_calculated_courses.csv",
                        mime="text/csv",
                        key="download_passed_btn"
                    )
                if failed_courses:
                    failed_df_export = pd.DataFrame(failed_courses)
                    csv_data_failed = failed_df_export.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ä¸‹è¼‰ä¸åŠæ ¼çš„ç§‘ç›®åˆ—è¡¨ç‚º CSV",
                        data=csv_data_failed,
                        file_name=f"{uploaded_file.name.replace('.pdf', '')}_failed_courses.csv",
                        mime="text/csv",
                        key="download_failed_btn"
                    )

        else:
            st.warning("æœªå¾ PDF ä¸­æå–åˆ°ä»»ä½•è¡¨æ ¼æ•¸æ“šã€‚è«‹æª¢æŸ¥ PDF å…§å®¹æˆ–å˜—è©¦ä¸Šå‚³å…¶ä»–æª”æ¡ˆã€‚")
    else:
        st.info("è«‹ä¸Šå‚³ PDF æª”æ¡ˆä»¥é–‹å§‹è™•ç†ã€‚")

if __name__ == "__main__":
    main()
